{
  "hash": "e74c51789b3dea8ae5b272a380af5ee8",
  "result": {
    "markdown": "---\ntitle: \"Introduction to Bayesian Statistics in R\"\ndate: '2022-12-11'\ncategories: [R]\n---\n\n\n## 1. บทนำ\n\nในการสร้างโมเดล Bayesian ใน R มีหลายแพ็กเกจที่ช่วยให้เราสามารถวิเคราะห์ข้อมูลได้ง่ายขึ้น โดยสองแพ็กเกจยอดนิยม ได้แก่ `{brms}` และ `{rstanarm}` ซึ่งทำให้สามารถสร้างโมเดล Bayesian Regression ได้โดยไม่ต้องเขียนโค้ด Stan เอง\n\n## 2. ติดตั้งและตั้งค่าแพ็กเกจ\n\nก่อนอื่นต้องติดตั้งและโหลดแพ็กเกจที่จำเป็น:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"brms\")\n#install.packages(\"rstanarm\")\n\nlibrary(brms)\nlibrary(rstanarm)\n```\n:::\n\n\n## 3. ตัวอย่างโมเดล Bayesian Linear Regression ด้วย {brms}\n\nเราจะลองสร้างโมเดล Bayesian Linear Regression โดยใช้ชุดข้อมูล `mtcars` เพื่อพยากรณ์ **mpg** (อัตราสิ้นเปลืองเชื้อเพลิง) จาก **hp** (แรงม้า)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# โมเดลเบื้องต้น\nbayes_model <- brm(\n  mpg ~ hp,\n  data = mtcars,\n  family = gaussian(),\n  prior = set_prior(\"normal(0, 10)\", class = \"b\"),\n  chains = 4,\n  iter = 2000,\n  warmup = 1000,\n  seed = 1234\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 5.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.51 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.034 seconds (Warm-up)\nChain 1:                0.015 seconds (Sampling)\nChain 1:                0.049 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 6e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.027 seconds (Warm-up)\nChain 2:                0.015 seconds (Sampling)\nChain 2:                0.042 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 6e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.023 seconds (Warm-up)\nChain 3:                0.015 seconds (Sampling)\nChain 3:                0.038 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.033 seconds (Warm-up)\nChain 4:                0.015 seconds (Sampling)\nChain 4:                0.048 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# สรุปผลโมเดล\nsummary(bayes_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: mpg ~ hp \n   Data: mtcars (Number of observations: 32) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    30.08      1.63    26.90    33.23 1.00     3431     2594\nhp           -0.07      0.01    -0.09    -0.05 1.00     3544     2507\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     3.97      0.54     3.08     5.18 1.00     2955     2388\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\n### การแปลผลลัพธ์ของโมเดล\n\nเมื่อเรียก `summary(bayes_model)` เราจะเห็นค่าประมาณของสัมประสิทธิ์ (Estimate) และค่าความไม่แน่นอน (Credible Interval) ซึ่งแตกต่างจากโมเดล Frequentist ที่ใช้ค่า p-value\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ตรวจสอบการแจกแจงพารามิเตอร์\nplot(bayes_model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nการพล็อตผลลัพธ์จะช่วยให้เราเห็นการกระจายตัวของพารามิเตอร์ รวมถึงตรวจสอบว่ามีความไม่แน่นอนมากน้อยเพียงใด\n\nฟังก์ชัน `brm()` มาจากแพ็กเกจ `{brms}` ใน R ซึ่งใช้สำหรับสร้างโมเดล Bayesian Generalized (Non-)Linear Models โดยทำให้เราสามารถใช้วิธี Bayesian Inference ได้ง่ายขึ้นผ่านการเขียนโค้ดคล้ายกับ `lm()` และ `glm()` ของ Frequentist\n\n## **โครงสร้างของฟังก์ชัน `brm()`**\n\n\n\n\n\n### **อธิบายอาร์กิวเมนต์หลัก**\n\n1.  **`formula`** – กำหนดสมการโมเดล เช่น `mpg ~ hp + wt`\n\n2.  **`data`** – ชุดข้อมูลที่ใช้สร้างโมเดล\n\n3.  **`family`** – กำหนดรูปแบบการแจกแจง เช่น\n\n    -   `gaussian()` (สำหรับข้อมูลต่อเนื่อง, เทียบเท่า Linear Regression)\n\n    -   `bernoulli()` (สำหรับข้อมูล binary, เทียบเท่า Logistic Regression)\n\n    -   `poisson()` (สำหรับข้อมูลนับ)\n\n4.  **`prior`** – กำหนด Prior Distribution ของพารามิเตอร์ เช่น\n\n    `prior = set_prior(\"normal(0, 10)\", class = \"b\")`\n\n    หากไม่กำหนด ค่า Prior จะถูกตั้งค่าเป็นค่าเริ่มต้นที่เหมาะสม\n\n5.  **`iter`** – จำนวน iteration ใน MCMC (ค่าเริ่มต้นคือ 2000)\n\n6.  **`chains`** – จำนวน Markov chains (ค่าเริ่มต้นคือ 4)\n\n7.  **`cores`** – จำนวนคอร์ของ CPU ที่ใช้ประมวลผล (ควรตั้งให้เท่ากับจำนวน chains เพื่อเพิ่มความเร็ว)\n\n8.  **`control`** – ปรับค่า parameter ของ NUTS sampler เช่น\n\n    -   `adapt_delta`: ค่าต่ำไปอาจทำให้เกิด divergent transitions (ค่าเริ่มต้น 0.8)\n\n## **ตัวอย่างการใช้งาน**\n\n### **1. โมเดล Bayesian Linear Regression**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)  \n# โหลดข้อมูล mtca\ndata(mtcars) \n# โมเดล: mpg~ hp \nbayes_model <- brm(\n  mpg ~ hp,\n  data = mtcars,\n  family = gaussian(),\n  prior = set_prior(\"normal(0, 10)\", class = \"b\"),\n  iter = 4000,\n  chains = 4,\n  cores = 4\n) \n```\n:::\n\n\n### **2. ตรวจสอบผลลัพธ์โมเดล**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(bayes_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: mpg ~ hp \n   Data: mtcars (Number of observations: 32) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    30.06      1.74    26.59    33.43 1.00     7296     5172\nhp           -0.07      0.01    -0.09    -0.05 1.00     7345     5303\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     3.99      0.54     3.10     5.24 1.00     6306     4946\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n# ตรวจสอบค่า Prior และ Posterior\nprior_summary(bayes_model)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|prior                   |class     |coef |group |resp |dpar |nlpar |lb |ub |source  |\n|:-----------------------|:---------|:----|:-----|:----|:----|:-----|:--|:--|:-------|\n|normal(0, 10)           |b         |     |      |     |     |      |   |   |user    |\n|                        |b         |hp   |      |     |     |      |   |   |default |\n|student_t(3, 19.2, 5.4) |Intercept |     |      |     |     |      |   |   |default |\n|student_t(3, 0, 5.4)    |sigma     |     |      |     |     |      |0  |   |default |\n\n</div>\n:::\n\n```{.r .cell-code}\n# ดูผลลัพธ์สรุปค่าประมาณของพารามิเตอร์\nsummary(bayes_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: mpg ~ hp \n   Data: mtcars (Number of observations: 32) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    30.06      1.74    26.59    33.43 1.00     7296     5172\nhp           -0.07      0.01    -0.09    -0.05 1.00     7345     5303\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     3.99      0.54     3.10     5.24 1.00     6306     4946\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n```{.r .cell-code}\n# พล็อตการแจกแจงของพารามิเตอร์ \nplot(bayes_model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# ตรวจสอบการรวมตัวของ Markov Chains \nmcmc_plot(bayes_model)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\n### **3. โมเดล Logistic Regression**\n\nถ้าเรามีตัวแปรเป้าหมายเป็นค่าทางเลือก (เช่น 0/1) เราสามารถใช้โมเดลโลจิสติกได้:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: am ~ hp + wt \n   Data: mtcars (Number of observations: 32) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    10.60      3.02     5.16    16.96 1.00     5778     5299\nhp            0.02      0.01     0.00     0.04 1.00     4579     4997\nwt           -4.55      1.16    -6.95    -2.38 1.00     4191     4230\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\n## **ข้อดีของ `brm()`**\n\n-   ใช้งานง่าย คล้ายกับ `lm()` และ `glm()`\n\n-   รองรับการใช้ Prior ทำให้สามารถควบคุมโมเดล Bayesian ได้\n\n-   ใช้ Stan เป็น backend ทำให้มีความยืดหยุ่นสูงและประสิทธิภาพดี\n\n-   รองรับโมเดลที่ซับซ้อน เช่น hierarchical models และ mixed-effects models\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}